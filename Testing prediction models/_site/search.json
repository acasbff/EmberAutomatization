[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Comparison between R and python functions for prediction",
    "section": "",
    "text": "Make test data from Ember EU data since 2019 with demand\n# download.file('https://ember-climate.org/app/uploads/2022/07/monthly_full_release_long_format-4.csv',\n#               paste0('monthly_full_release_long_format-4_',\n#                      str_remove_all(Sys.Date(), \"-\"), \".csv\"), mode = \"wb\")\n\nEU_subset &lt;- read_csv(\"monthly_full_release_long_format-4_20240826.csv\", \n                      show_col_types = FALSE) %&gt;% \n  filter(Variable %in% 'Demand', EU == 1, Date &gt;= \"2019-01-01\") %&gt;% \n  select(Area, Date, Value)"
  },
  {
    "objectID": "index.html#run-predictions-with-python-models",
    "href": "index.html#run-predictions-with-python-models",
    "title": "Comparison between R and python functions for prediction",
    "section": "Run predictions with python models",
    "text": "Run predictions with python models\n\nARIMA (pmdarima): Uses auto_arima with seasonal=True and m=12 for automatic model selection, handling seasonality with a 12-month cycle.\nProphet: Employs default settings, which include automatic changepoint detection and yearly seasonality.\nARIMA (scikit-learn): Implements a custom ARIMA estimator with fixed order (1,1,1), suitable for integration with scikit-learnâ€™s API.\n\n\n\nCode\n## code developed with cursor\n## ## to install packages: /Users/acas/miniconda3/envs/r-reticulate/bin/pip install fbprophet\n\nimport sys\nimport os\nimport pandas as pd\nimport numpy as np\nfrom pmdarima import auto_arima\nfrom prophet import Prophet\n\n\nImporting plotly failed. Interactive plots will not work.\n\n\nCode\nfrom sklearn.base import BaseEstimator, RegressorMixin\nfrom statsmodels.tsa.arima.model import ARIMA as StatsmodelsARIMA\nfrom sklearn.metrics import r2_score\nimport warnings\nimport traceback\nimport logging\n\nlogger = logging.getLogger('cmdstanpy')\nlogger.addHandler(logging.NullHandler())\nlogger.propagate = False\nlogger.setLevel(logging.CRITICAL)\nlogging.getLogger('prophet').setLevel(logging.CRITICAL)\n\n   \n# Suppress warnings\nwarnings.filterwarnings(\"ignore\")\n\n### load r object\ndfr = pd.DataFrame(r.EU_subset)\ndfr['Date'] = pd.to_datetime(dfr['Date'])\n\ndf = dfr\n\n# print(dfr)\n# print(dfr.dtypes)\n\n# # Load the data - if needed to load locally \n# df = pd.read_csv('/Users/acas/Dropbox/BFF/projects/QuaterlyReports/Ember_API_python/EU_subset.txt', \n#                  sep='\\t', parse_dates=['Date'])\n# print(df)\n# print(df.dtypes)\n\n# After loading, let's resample the data to monthly frequency\ndf['Date'] = pd.to_datetime(df['Date']).dt.to_period('M').dt.to_timestamp()\ndf = df.groupby(['Date', 'Area'])['Value'].mean().reset_index()\n\n# Set the date range for training and testing\ntrain_end = '2023-05-01'\ntest_start = '2023-06-01'\ntest_end = '2024-05-31'\n\n### functions to do predictions\n\nclass ARIMAEstimator(BaseEstimator, RegressorMixin):\n    def __init__(self, order=(1,1,1)):\n        self.order = order\n    \n    def fit(self, X, y=None):\n        self.model_ = StatsmodelsARIMA(y, order=self.order)\n        self.results_ = self.model_.fit()\n        return self\n    \n    def predict(self, X):\n        return self.results_.forecast(steps=len(X))\n\ndef fit_and_forecast(country_data, train_end, test_start, test_end):\n    # Ensure data is sorted by date\n    country_data = country_data.sort_index()\n\n    # Convert all date strings to datetime\n    train_end_dt = pd.to_datetime(train_end)\n    test_start_dt = pd.to_datetime(test_start)\n    test_end_dt = pd.to_datetime(test_end)\n\n    # Use all data up to and including the train_end month\n    train = country_data[country_data.index &lt;= train_end_dt]\n    \n    # print(f\"Train date range: {train.index.min()} to {train.index.max()}\")\n\n    # Calculate the number of months between test_start and test_end\n    test_months = pd.date_range(start=test_start_dt, end=test_end_dt, freq='MS').shape[0]\n\n    # Generate forecast dates for the specified test period\n    forecast_dates = pd.date_range(start=test_start_dt, end=test_end_dt, freq='MS')\n\n    # Fit the pmdarima model\n    model_pmdarima = auto_arima(train['Value'], seasonal=True, m=12, suppress_warnings=True)\n    forecast_pmdarima, conf_int = model_pmdarima.predict(n_periods=test_months, return_conf_int=True)\n\n    # Fit the Prophet model\n    train_prophet = train.reset_index().rename(columns={'Date': 'ds', 'Value': 'y'})\n    model_prophet = Prophet()\n    model_prophet.fit(train_prophet)\n    future_dates = pd.DataFrame({'ds': forecast_dates})\n    forecast_prophet = model_prophet.predict(future_dates)['yhat']\n\n    # Fit the scikit-learn ARIMA model\n    model_sklearn = ARIMAEstimator(order=(1,1,1))\n    model_sklearn.fit(train.index, train['Value'])\n    forecast_sklearn = model_sklearn.predict(forecast_dates)\n\n    # Get actual values for the forecast period if available\n    actual = country_data[(country_data.index &gt;= test_start_dt) & (country_data.index &lt;= test_end_dt)]['Value']\n    \n    # print(f\"Forecast length: {len(forecast_pmdarima)}\")\n    # print(f\"Forecast date range: {forecast_dates[0]} to {forecast_dates[-1]}\")\n\n    # Create DataFrame with forecast and available actual data\n    result_df = pd.DataFrame({\n        'Date': forecast_dates,\n        'Actual': actual.reindex(forecast_dates),\n        'pmdarima': forecast_pmdarima,\n        'prophet': forecast_prophet.values,\n        'sklearn_arima': forecast_sklearn,\n        'Lower_CI': conf_int[:, 0],\n        'Upper_CI': conf_int[:, 1]\n    })\n    \n    return result_df\n\n### Process countries and get results\nall_results = []\nfor country in df['Area'].unique():\n    #print(f\"\\nProcessing {country}...\")\n    country_data = df[df['Area'] == country].set_index('Date')\n    try:\n        country_results = fit_and_forecast(country_data, train_end, test_start, test_end)\n        country_results['Area'] = country\n        all_results.append(country_results)\n    except Exception as e:\n        print(f\"Error processing {country}: {str(e)}\")\n        print(f\"Traceback: {traceback.format_exc()}\")\n\n### Combine all results\nif all_results:\n    final_results = pd.concat(all_results, ignore_index=True)\n\n    # Export results to CSV\n    final_results.to_csv('multi_country_comparison.csv', index=False)\n    #print(\"\\nComparison data exported to multi_country_comparison.csv\")\nelse:\n    print(\"No results were generated. Please check the errors above.\")"
  },
  {
    "objectID": "index.html#run-predictions-with-r-models",
    "href": "index.html#run-predictions-with-r-models",
    "title": "Comparison between R and python functions for prediction",
    "section": "Run predictions with R models",
    "text": "Run predictions with R models\n\nauto.arima: Automatically selects the best ARIMA model based on AIC, BIC or AICc value. The process involves:\n\nStarting with a default model (usually ARIMA(2,1,2) for non-seasonal data)\nVarying the parameters (p,d,q) stepwise and fitting multiple models\nComparing models using the specified information criterion (default is AICc)\nOptionally performing stepwise selection to refine the model further\nChoosing the model with the lowest information criterion value as the best fit\n\nETS: Fits an ExponenTial Smoothing model, automatically selecting the best model from various options (trend, seasonality, error types).\nTBATS: Implements Trigonometric, Box-Cox transform, ARMA errors, Trend, and Seasonal components model. TBATS is particularly useful for time series with complex seasonal patterns that are difficult to capture with traditional methods.\nNNETAR: Fits a feed-forward neural network model with autoregressive inputs, using default settings for network architecture.\nSTLM: Applies Seasonal and Trend decomposition using Loess (STL) with a chosen forecasting method (default is ETS) for the seasonally adjusted data.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(forecast)\nlibrary(lubridate)\nlibrary(urca)\n\ndf &lt;- EU_subset\n# Read the data if needed\n#df &lt;- read_delim(\"/Users/acas/Dropbox/BFF/projects/QuaterlyReports/Ember_API_python/EU_subset.txt\")\n\n# Function to analyze a single country\nanalyze_country &lt;- function(country_data) {\n  tryCatch({\n    # Check if there's enough data\n    if (nrow(country_data) &lt; 24) {\n      stop(\"Not enough data for analysis (less than 24 months)\")\n    }\n    \n    # Split data into training and test sets\n    train_data &lt;- country_data[country_data$Date &lt;= as.Date(\"2023-05-01\"), ]\n    test_data &lt;- country_data[country_data$Date &gt;= as.Date(\"2023-05-01\") & country_data$Date &lt; as.Date(\"2024-05-01\"), ]\n    \n    if (nrow(train_data) &lt; 12 || nrow(test_data) &lt; 12) {\n      stop(\"Insufficient data for train or test set (less than 12 months)\")\n    }\n    \n    # Create time series object\n    ts_train &lt;- ts(train_data$Value, frequency=12, start=c(year(min(train_data$Date)), month(min(train_data$Date))))\n    \n    # Fit models and forecast\n    # 1. auto.arima\n    auto_model &lt;- auto.arima(ts_train)\n    auto_forecast &lt;- forecast(auto_model, h=12)\n    \n    # 2. ETS\n    ets_model &lt;- ets(ts_train)\n    ets_forecast &lt;- forecast(ets_model, h=12)\n    \n    # 3. TBATS\n    tbats_model &lt;- tbats(ts_train)\n    tbats_forecast &lt;- forecast(tbats_model, h=12)\n    \n    # 4. NNETAR\n    nnetar_model &lt;- nnetar(ts_train)\n    nnetar_forecast &lt;- forecast(nnetar_model, h=12)\n    \n    # 5. STLM\n    stlm_model &lt;- stlm(ts_train)\n    stlm_forecast &lt;- forecast(stlm_model, h=12)\n    \n    plot_data &lt;- filter(country_data, Date &gt; as.Date(\"2023-05-01\") & Date &lt; as.Date(\"2024-06-01\")) %&gt;%\n      rename(Actual = Value) %&gt;%\n      left_join(data.frame(\n        Date = seq.Date(from = as.Date(\"2023-06-01\"), by = \"month\", length.out = 12),\n        AutoArima_R = as.numeric(auto_forecast$mean),\n        ETS_R = as.numeric(ets_forecast$mean),\n        TBATS_R = as.numeric(tbats_forecast$mean),\n        NNETAR_R = as.numeric(nnetar_forecast$mean),\n        STLM_R = as.numeric(stlm_forecast$mean)\n      ), by = join_by(Date))\n    \n    return(plot_data)\n  }, error = function(e) {\n    warning(paste(\"Error processing country:\", unique(country_data$Area), \"-\", e$message))\n    return(NULL)\n  })\n}\n\n# Analyze all countries\nRresults &lt;- df %&gt;%\n  group_by(Area) %&gt;%\n  group_modify(~analyze_country(.x)) %&gt;%\n  filter(!is.null(.)) %&gt;% \n  ungroup()"
  },
  {
    "objectID": "index.html#comparing-the-different-forecasting-models-for-each-country",
    "href": "index.html#comparing-the-different-forecasting-models-for-each-country",
    "title": "Comparison between R and python functions for prediction",
    "section": "Comparing the different forecasting models for each country",
    "text": "Comparing the different forecasting models for each country\n\n\nCode\npyResults &lt;- reticulate::py$final_results # Access the Python object ### not sure why it stopped working\n\n### if needed\npyResults &lt;- read_csv(\"/Users/acas/Dropbox/BFF/projects/QuaterlyReports/Ember_API_python/multi_country_comparison.csv\") \n\ncomp &lt;- full_join(Rresults, pyResults, copy = TRUE) %&gt;% \nrename(\"Arima_R\" =\"AutoArima_R\",   \"sklearn_Py\"=\"sklearn_arima\", \n       \"prophet_Py\"= \"prophet\" , \"pmdarima_Py\"=\"pmdarima\")\n\n# Overview per country\ncomp %&gt;%\n  pivot_longer(Arima_R:sklearn_Py) %&gt;%\n  ggplot(aes(x = Actual, y = value, color = name, linetype = grepl(\"_R$\", name))) +\n  geom_abline() +\n  geom_smooth(method = 'lm', se = FALSE) +\n  #geom_point() +\n  facet_wrap(~Area, scales = 'free', ncol = 4) +\n  theme_bw() +\n  labs(title = \"Comparison of Different Forecasting Models\",\n       x = \"Actual Values\",\n       y = \"Forecasted Values\",\n       color = \"Model\",\n       linetype = \"R Model\") +\n  scale_linetype_manual(values = c(\"solid\", \"dotted\")) +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "index.html#comparing-models-using-2-metrics",
    "href": "index.html#comparing-models-using-2-metrics",
    "title": "Comparison between R and python functions for prediction",
    "section": "Comparing models using 2 metrics",
    "text": "Comparing models using 2 metrics\n\nMean Absolute Percentage Error (MAPE): Measures the average percentage difference between predicted and actual values. Itâ€™s scale-independent, making it useful for comparing forecasts across different datasets.\nRoot Mean Square Error (RMSE): Measures the standard deviation of the residuals (prediction errors). Itâ€™s more sensitive to large errors and is in the same units as the response variable.\nIf a model has low RMSE but high MAPE, it might be making large percentage errors on smaller values, while if a model has high RMSE but low MAPE, it might be making consistent percentage errors across all scales, but with some larger absolute errors.\n\n\n\nCode\nmodels &lt;- c(\"STLM_R\", \"TBATS_R\", \"NNETAR_R\", \"ETS_R\", \"Arima_R\",\"sklearn_Py\", \"prophet_Py\", \"pmdarima_Py\")\n\ncalculate_mape &lt;- function(actual, predicted) {\n  mean(abs((actual - predicted) / actual), na.rm = TRUE) * 100\n}\n\n# Function to calculate MAPE\ncalculate_mape &lt;- function(actual, predicted) {\n  mean(abs((actual - predicted) / actual), na.rm = TRUE) * 100\n}\n\n# Function to calculate RMSE\ncalculate_rmse &lt;- function(actual, predicted) {\n  sqrt(mean((actual - predicted)^2, na.rm = TRUE))\n}\n\n# Calculate metrics for each country\nmetrics_list &lt;- comp %&gt;%\n  group_by(Area) %&gt;%\n  group_map(~ {\n    mape_results &lt;- sapply(models, function(model) {\n      calculate_mape(.x$Actual, .x[[model]])\n    })\n    rmse_results &lt;- sapply(models, function(model) {\n      calculate_rmse(.x$Actual, .x[[model]])\n    })\n    data.frame(\n      Area = .y$Area,\n      Model = models,\n      MAPE = mape_results,\n      RMSE = rmse_results\n    )\n  })\n\n# Combine results into a single dataframe\nmetrics_df &lt;- do.call(rbind, metrics_list)\n\nmetrics_long &lt;- metrics_df %&gt;%\n  pivot_longer(cols = c(RMSE, MAPE), names_to = \"Metric\", values_to = \"Value\")\n\nmetrics_long %&gt;%\n  group_by(Metric, Model) %&gt;%\n  summarise(Median = median(Value, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  group_by(Metric) %&gt;%\n  mutate(Is_Lowest = Median == min(Median, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  right_join(metrics_long, by = c(\"Metric\", \"Model\")) %&gt;%\n  ggplot(aes(x = fct_rev(fct_inorder(Model)), \n             y = Value)) +\n  geom_boxplot(aes(fill = Is_Lowest), outliers = FALSE) +\n  geom_point(alpha = 0.5, position = position_jitter(width = 0.2, height = 0)) +\n  facet_wrap(~ Metric, scales = \"free_x\", ncol = 2) +\n  coord_flip() +\n  scale_fill_manual(values = c(\"TRUE\" = \"lightgreen\", \"FALSE\" = \"white\")) +\n  theme_bw() +\n  labs(title = \"Comparison of Models based on RMSE and MAPE metrics\",\n       subtitle = \"The lower the better, highlighting green the model with the lowest median\",\n       x = NULL, \n       y = NULL) +\n  theme(legend.position = 'none',\n        strip.background = element_rect(fill = \"lightgrey\"),\n        strip.text = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\n\nFinal visualization comparing the top-performing models (Arima_R, STLM_R, and pmdarima_Py)\n\n\nCode\ncomp %&gt;%\n  pivot_longer(c(Arima_R, STLM_R, pmdarima_Py)) %&gt;%\n  ggplot(aes(x = Actual, y = value, color = name)) +\n  geom_abline() +\n  geom_smooth(method = 'lm', se = FALSE) +\n  #geom_point() +\n  #facet_wrap(~Area, scales = 'free') +\n  theme_bw() +\n  labs(title = \"Comparison of different forecasting models\",\n       x = \"Actual Values\",\n       y = \"Forecasted Values\",\n       color = \"Model\",\n       linetype = \"R Model\") \n\n\n\n\n\n\n\n\n\n\n\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Monterey 12.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Lisbon\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] urca_1.3-4        forecast_8.23.0   reticulate_1.38.0 lubridate_1.9.3  \n [5] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2      \n [9] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n[13] tidyverse_2.0.0  \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5      xfun_0.46         htmlwidgets_1.6.4 lattice_0.22-6   \n [5] tzdb_0.4.0        quadprog_1.5-8    vctrs_0.6.5       tools_4.4.0      \n [9] generics_0.1.3    curl_5.2.1        parallel_4.4.0    fansi_1.0.6      \n[13] xts_0.14.0        pkgconfig_2.0.3   Matrix_1.7-0      lifecycle_1.0.4  \n[17] farver_2.1.2      compiler_4.4.0    munsell_0.5.1     codetools_0.2-20 \n[21] htmltools_0.5.8.1 yaml_2.3.10       pillar_1.9.0      crayon_1.5.3     \n[25] nlme_3.1-165      fracdiff_1.5-3    tidyselect_1.2.1  digest_0.6.36    \n[29] stringi_1.8.4     labeling_0.4.3    splines_4.4.0     tseries_0.10-56  \n[33] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.0        here_1.0.1       \n[37] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    utf8_1.2.4       \n[41] withr_3.0.1       scales_1.3.0      bit64_4.0.5       timechange_0.3.0 \n[45] TTR_0.24.4        rmarkdown_2.27    quantmod_0.4.26   bit_4.0.5        \n[49] nnet_7.3-19       timeDate_4032.109 zoo_1.8-12        png_0.1-8        \n[53] hms_1.1.3         evaluate_0.24.0   knitr_1.48        lmtest_0.9-40    \n[57] mgcv_1.9-1        rlang_1.1.4       Rcpp_1.0.13       glue_1.7.0       \n[61] rstudioapi_0.16.0 vroom_1.6.5       jsonlite_1.8.8    R6_2.5.1"
  }
]